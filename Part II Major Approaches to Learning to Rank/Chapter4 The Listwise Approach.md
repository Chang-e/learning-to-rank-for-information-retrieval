# 基于列表的方法

**摘要：**在本章中，我们介绍了基于列表的学习排名方法。 具体来说，我们首先介绍那些最小化特定度量的损失函数的基于列表的算法（也称为直接优化方法），然后介绍一些损失函数与评估方法不直接相关的的其他信息检索算法。

## 4.1 概述

基于列表的方法将与训练数据中的查询相关联的整个文档集作为输入，并预测其标注标签。 根据使用的损失函数，该方法可以分为两个子类别。 第一个子类别的损失函数与评估度量明确相关（例如，基于度量的排名误差的近似值或上限）。 示例算法包括[5、7、25、27、32-34、36、37]。 由于损失函数和评估指标之间的密切关系，这些算法也被称为直接优化方法。 第二个子类别的损失函数与评估指标没有明确关系。 示例算法包括[4，16，30，31]。 在本章的其余部分，我们将介绍这两个子类别及其代表算法。

请注意，基于列表的方法假设根据排列给出正确的标注标签，但是判断排列可能采用其他形式（例如关联度或成对偏好）。 在这种情况下，我们将使用等效置换集的概念（表示为$\Omega_y$，请参见第1章）来弥合差距。 对于$\Omega_y$，我们使用$L(f;x,\Omega_y)$表示基于列表的方法的损失函数。 但是，为了便于讨论，如果根据每个单个文档的相关度是由$\Omega_y$生成，有时会将损失函数写为$L(f;x,y)$。

此外，诸如MAP和NDCG的评估方法也可以以$\Omega_y$的形式重写。 例如，我们可以如下重写NDCG：
$$
NDCG(\pi, \Omega_y)=\frac{1}{Z_m}\sum_{j=1}^{m}{G(l_{\pi^{-1}(\pi_y(j))})\eta(\pi_y(j))}, \ \forall\pi_y\in\omega_y \tag{4.1}
$$
同样，为了便于讨论，有时我们也将NDCG写为$NDCG(\pi,y)$或$NDCG(f,x,y)$（当$\pi=sort\ \circ\ f(x)$时）。

## 4.2 最小化度量损失

通过直接优化用于评估排名表现的内容来学习排序模型可能是最直接的选择。这正是基于列表的方法的第一个子类别的动机，即直接优化方法。但是，这项任务并不像看起来那么琐碎。如前所述，诸如NDCG和MAP之类的评估指标都是基于位置的，因此是不连续且不可微的[26，33]。优化此类目标函数的困难源于以下事实：大多数现有的优化技术都是为处理连续和可区分的情况而开发的。

为了应对挑战，已经进行了几次尝试。首先，可以选择优化基于量度的排名误差的连续可微近似。这样，可以利用许多现有的优化技术，示例算法包括SoftRank [27]，Approximate Rank [25]和SmoothRank [7]。第二，可以用优化一个连续可微的界限函数（有时甚至是凸的）来替代度量排序误差，示例算法包括SVMmap [36]，SVMndcg [5]和PermuRank [33]（实际上，此技巧也已用于分类。 也就是说，由于0-1分类损失是不可微的，因此使用了像指数损失这样的凸上限。）。第三，可以选择使用能够优化非平滑目标的优化技术。例如，可以为利用Boosting框架（相应的算法称为AdaRank [32]），或采用遗传算法进行优化（相应的算法称为RankGP [34]）。

### 4.2.1 度量近似

#### 4.2.1.1 SoftRank

在SoftRank [27]中，假定不是简单地通过根据评分功能进行排序来确定文档的排名。 取而代之的是，它通过将文档的实际分数视为随机变量来将随机性引入排序过程，该随机变量的均值是评分函数给出的分数。 这样，文档很可能可以在任何位置排名，当然也会具有不同的概率。 对于每个这样的可能排名，可以计算NDCG值。 然后，可以将NDCG对所有可能排名的期望用作原始评估指标NDCG的平滑近似。 实现此目标的详细步骤如下。

首先，定义分数分布。 给定$x=\{x_j\}_{j=1}^m$与训练查询$q$相关联，文档$x_j$的分数$s_j$不再是确定性值，而是随机变量。 随机变量由高斯分布控制，其方差为$\sigma_s$，平均值为$f(x_j)$，即得分函数输出的原始得分。 于是有
$$
p(s_j)=N(s_j|f(x_j), \sigma_x^2) \tag{4.2}
$$
第二，定义排序分布。 由于分数的随机性，每个文档都有可能在任何位置排名。具体地，基于得分分布，可以推论出文档$x_u$被排在另一个文档$x_v$之前的概率如下：
$$
P_{u,v}=\int_0^\infty{N(s|f(x_u)-f(x_v),2\sigma_s^2)}ds \tag{4.3}
$$
在此基础上，可以通过将文档一个接一个地添加到排名列表中，以迭代方式得出排名分布。 假设我们已经在排名列表中包含文档$x_j$，则在添加文档$x_u$时，如果文档$x_u$可以击败$x_jj$，则$x_j$的排名将增加1。 否则，$x_j$的等级将保持不变。 在数学上，可以将$x_j$排在位置$r$上的概率（表示为$P_j(r)$）计算如下：
$$
P_j^{(u)}(r)=P_j^{(u-1)}(r-1)P_{u,j}+P_j^{(u-1)}(r)(1-P_{u,j}) \tag{4.4}
$$
第三，利用等级分布，可以计算NDCG的期望值（称为SoftNDCG（为了便于参考，我们还将诸如SoftNDCG的目标函数称为替代指标。）），并在学习排序时使用$(1- SoftNDCG)$作为损失函数：
$$
L(f;x,y)=1-\frac{1}{Z_m}\sum_{j=1}^m{(2^{y_j}-1)}\sum_{r=1}^m{P_j(r)} \tag{4.5}
$$
为了通过最小化上述损失函数来学习排序模型$f$，可以使用神经网络作为模型，并采用梯度下降作为优化算法。

在[14]中，高斯过程用于进一步增强SoftRank算法，其中$\sigma_s$不再是预先指定的常数，而是学习的参数。 在[35]中，SoftRank方法进一步扩展为近似P@k和AP。相应的目标函数分别命名为SoftPC和SoftAP。

#### 4.2.1.2 排序的决策理论框架

在[37]中，提出了与SoftRank类似的想法，该想法使用决策理论框架来优化预期的评估措施。 首先，定义排序实例。 例如，实例可以是任何评估指标。 假设效用表示为$U(·)$，则将以下期望效用作为学习目标：
$$
\tilde{U}(w;x,y)=E_{p(s|X,w)}[U(s,y)] \tag{4.6}
$$
其中$w$表示排序函数的参数，而$s$是文档的排序分数。

根据以上定义，尽管实例本身可能是不连续不可微的，但它不包含任何模型参数，也不会给学习过程带来麻烦，实际上包含模型参数的是条件概率$p(s|x,w)$。

在[37]中，假设文档之间的独立性（即，$p(s|x,w)=\Pi_jp(s_j|x_j,w)$，并且使用广义线性模型[22]来定义$p(s_j|x_j,w)p$，每个单个文档的条件概率。 广义线性模型包括似然模型$p(y |\theta)$，输入和模型参数的线性组合$w^Tx$以及将参数$\theta$映射到实线的链接函数。 特别地，在[37]中将二项式函数（即$Bin(·)$）用作似然模型，并使用累积正态函数（即$\psi(·)$）来定义
概率链接功能：
$$
p(s_j|X,w)=Bin(s_j;\psi(w^Tx;0,\frac{1}{\pi}),m) \tag{4.7}
$$
其中$m$是文档的数量。

然后，该算法使期望效用最大化（等效地，负效用可以视为损失函数）。 特别地，使用具有分解高斯先验的近似贝叶斯推断[18]来学习模型参数。

注意，除了优化评估方法之外，决策理论框架还可以用于优化其他实例，例如，用户单击文档的可能性。

#### 4.2.1.3 近似排序

在[25]中，Qin等人指出评估方法不佳的根本原因是排序位置相对于等级分数不好。 因此，他们建议使用排序分数的平滑函数对排名位置进行近似计算，从而使近似评估方法变得可区分且更易于优化。

这里我们以NDCG为例来说明近似过程。 同样的想法也适用于MAP。 有关更多详细信息，请参阅[25]。

如果将NDCG定义中的累计索引（请参见第1章）从排位结果中的位置更改为文档的索引，则NDCG可以重写为：
$$
Z_m^{-1}\sum_j{\frac{G(y_j)}{log(1+\pi(x_j))}} \tag{4.8}
$$
其中$\pi(x_j)$是文档$x_j$在排序结果$\pi$中的位置，他可以这么计算：
$$
\pi(x_j)=1+\sum_{u\neq j}{I_{\{f{x_j}-f{x_u}<0\}}} \tag{4.9}
$$
请注意，尽管此处的贴现函数$\eta(r)$有很多可靠的表达方式，此处我们可以直接定义$\eta(r)=\frac{1}{log(1+r)}$是为了简化。

从式（4.9）中，可以清楚地看到NDCG的非平滑特性来自何处。 实际上，NDCG是排名位置的平滑函数，但是，由于指标函数，排名位置是排名分数的非平滑函数。

[25]中的关键思想是通过S型函数[4]来近似指标函数，以便可以通过排名分数的平滑函数来近似位置。请注意，sigmoid函数是是一族函数，如广泛使用的逻辑函数，其他族成员包括普通的反正切函数，双曲正切函数和误差函数。 这里以逻辑函数为例。
$$
\hat{\pi}(x_j)=1+\sum_{u\neq j}{\frac{exp(-\alpha(f(x_j)-f(x_u)))}{1+exp(-\alpha(f(x_j)-f(x_u)))}} \tag{4.10}
$$
其中$\alpha>0$是一个比例常数。

通过（4.8）替换$\pi(x_j)$到$\hat{\pi}(x_j)$，可以得到NDCG的近似值（表示为AppNDCG），然后将损失函数定义为$(1-AppNDCG)$，
$$
L(f;x,y)=1-Z_m^{-1}\sum_{j=1}^m{\frac{G(y_j)}{log(1+\hat{\pi}(x_j))}} \tag{4.11}
$$
由于这种损失函数是连续的，并且相对于评分函数是微分的，因此可以简单地使用梯度下降法将其最小化。

在[25]中分析了近似精度。 基本结论是，当$\alpha$设置得足够大时，近似值可以变得非常准确。 换句话说，如果可以找到预期的损失函数的最优值，那么很可能也可以得到NDCG的最优值。

请注意，近似值越精确，损失函数就越“不平滑”。 相应地，优化过程变得不那么健壮。 通常需要采用一些鲁棒的优化算法，例如模拟退火或随机优化，以确保找到针对优化问题的良好解决方案。

#### 4.2.1.4 SmoothRank

在[7]中，提出了与近似等级相似的想法，即通过近似排名位置来平滑评估测量，两者轻微的区别在于定义逼近器的方式和执行优化的方式。

同样，这里我们以NDCG为例进行说明。 请注意，相同的想法也适用于MAP和许多其他评估措施。

在[7]中，通过使用文档的索引和排名结果中的位置来重写NDCG：
$$
\sum_{j=1}^m{\sum_{u=1}^m{G(y_{\pi^{-1}(u)})\eta(u)I_{x_j=x_{\pi}-l_{(u)}}}} \tag{4.12}
$$
其中$I_{x_j=x_{\pi}-l_{(u)}}$表示文档$x_j$是否在排序的第$u$个位置。

然后使用下列函数对$I_{x_j=x_{\pi}-l_{(u)}}$进行了平滑。
$$
h_{ju}=\frac{e^{-(f(x_j)-f(x_{\pi^{-1}(u)}))^2/\sigma}}{\sum_{l=1}^me^{-(f(x_j)-f(x_{\pi^{-1}(u)}))^2/\sigma}} \tag{4.13}
$$
有了$h_{ju}$，就可以得到NDCG的平滑版本，并在其基础上定义损失函数：
$$
\begin{align*}
L(f;x,y)&=1-\sum_{j=1}^m{\sum_{u=1}^m{G(y_{\pi^{-1}(u)})\eta(u)}h_{ju}} \\
&=1-\sum_{j=1}^m{\sum_{u=1}^m{G(y_{\pi^{-1}(u)})\eta(u)\frac{e^{-(f(x_j)-f(x_{\pi^{-1}(u)}))^2/\sigma}}{\sum_{l=1}^me^{-(f(x_j)-f(x_{\pi^{-1}(u)}))^2/\sigma}}}}
\end{align*}
\tag{4.14}
$$
显然，$h_{ju}$是得分函数$f$的连续函数，上述损失函数也是如此。 因此，可以使用梯度下降法对其进行优化。

与关于近似排序的讨论类似，平滑参数$\sigma$的选择也很关键：一方面，如果它很小，则目标函数将非常接近原始评估指标，因此高度不平滑且难以优化，而如果目标函数较大，则目标函数是平滑且易于优化的，但与相应的评估方法有很大不同。在[7]中，使用确定性退火策略来辅助优化。此过程可以看作是构造一系列函数的同伦方法：第一个函数易于优化，最后一个是期望的函数，中间的每个函数都可以看作是前一个函数的变形函数。 同伦方法从先前函数开始一个接着一个最小化系列内的每个函数，特别地，变形受$\simga$控制，从大$\simga$开始，逐步最小化越来越小的$\simga$对应的函数。



替代地优化基于度量的排名误差的连续且有区别的（有时甚至是凸的）界限。示例算法包括SVMmap [36]，SVMndcg [5]和PermuRank [33] .1。第三，可以选择使用能够优化非平滑目标的优化技术。例如，可以为此目的利用Boosting框架（相应的算法称为AdaRank [32]），或采用遗传算法进行优化（相应的算法称为RankGP [34]）。