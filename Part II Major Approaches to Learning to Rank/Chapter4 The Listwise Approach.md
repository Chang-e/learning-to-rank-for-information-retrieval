# 基于列表的方法

**摘要：**在本章中，我们介绍了基于列表的学习排名方法。 具体来说，我们首先介绍那些最小化特定度量的损失函数的基于列表的算法（也称为直接优化方法），然后介绍一些损失函数与评估方法不直接相关的的其他信息检索算法。

## 4.1 概述

基于列表的方法将与训练数据中的查询相关联的整个文档集作为输入，并预测其标注标签。 根据使用的损失函数，该方法可以分为两个子类别。 第一个子类别的损失函数与评估度量明确相关（例如，基于度量的排名误差的近似值或上限）。 示例算法包括[5、7、25、27、32-34、36、37]。 由于损失函数和评估指标之间的密切关系，这些算法也被称为直接优化方法。 第二个子类别的损失函数与评估指标没有明确关系。 示例算法包括[4，16，30，31]。 在本章的其余部分，我们将介绍这两个子类别及其代表算法。

请注意，基于列表的方法假设根据排列给出正确的标注标签，但是判断排列可能采用其他形式（例如关联度或成对偏好）。 在这种情况下，我们将使用等效置换集的概念（表示为$\Omega_y$，请参见第1章）来弥合差距。 对于$\Omega_y$，我们使用$L(f;x,\Omega_y)$表示基于列表的方法的损失函数。 但是，为了便于讨论，如果根据每个单个文档的相关度是由$\Omega_y$生成，有时会将损失函数写为$L(f;x,y)$。

此外，诸如MAP和NDCG的评估方法也可以以$\Omega_y$的形式重写。 例如，我们可以如下重写NDCG：
$$
NDCG(\pi, \Omega_y)=\frac{1}{Z_m}\sum_{j=1}^{m}{G(l_{\pi^{-1}(\pi_y(j))})\eta(\pi_y(j))}, \ \forall\pi_y\in\omega_y \tag{4.1}
$$
同样，为了便于讨论，有时我们也将NDCG写为$NDCG(\pi,y)$或$NDCG(f,x,y)$（当$\pi=sort\ \circ\ f(x)$时）。

## 4.2 最小化度量损失

通过直接优化用于评估排名表现的内容来学习排序模型可能是最直接的选择。这正是基于列表的方法的第一个子类别的动机，即直接优化方法。但是，这项任务并不像看起来那么琐碎。如前所述，诸如NDCG和MAP之类的评估指标都是基于位置的，因此是不连续且不可微的[26，33]。优化此类目标函数的困难源于以下事实：大多数现有的优化技术都是为处理连续和可区分的情况而开发的。

为了应对挑战，已经进行了几次尝试。首先，可以选择优化基于量度的排名误差的连续可微近似。这样，可以利用许多现有的优化技术，示例算法包括SoftRank [27]，Approximate Rank [25]和SmoothRank [7]。第二，可以用优化一个连续可微的界限函数（有时甚至是凸的）来替代度量排序误差，示例算法包括SVMmap [36]，SVMndcg [5]和PermuRank [33]（实际上，此技巧也已用于分类。 也就是说，由于0-1分类损失是不可微的，因此使用了像指数损失这样的凸上限。）。第三，可以选择使用能够优化非平滑目标的优化技术。例如，可以为利用Boosting框架（相应的算法称为AdaRank [32]），或采用遗传算法进行优化（相应的算法称为RankGP [34]）。

### 4.2.1 度量近似

#### 4.2.1.1 SoftRank

在SoftRank [27]中，假定不是简单地通过根据评分功能进行排序来确定文档的排名。 取而代之的是，它通过将文档的实际分数视为随机变量来将随机性引入排序过程，该随机变量的均值是评分函数给出的分数。 这样，文档很可能可以在任何位置排名，当然也会具有不同的概率。 对于每个这样的可能排名，可以计算NDCG值。 然后，可以将NDCG对所有可能排名的期望用作原始评估指标NDCG的平滑近似。 实现此目标的详细步骤如下。

首先，定义分数分布。 给定$x=\{x_j\}_{j=1}^m$与训练查询$q$相关联，文档$x_j$的分数$s_j$不再是确定性值，而是随机变量。 随机变量由高斯分布控制，其方差为$\sigma_s$，平均值为$f(x_j)$，即得分函数输出的原始得分。 于是有
$$
p(s_j)=N(s_j|f(x_j), \sigma_x^2) \tag{4.2}
$$
第二，定义排序分布。 由于分数的随机性，每个文档都有可能在任何位置排名。具体地，基于得分分布，可以推论出文档$x_u$被排在另一个文档$x_v$之前的概率如下：
$$
P_{u,v}=\int_0^\infty{N(s|f(x_u)-f(x_v),2\sigma_s^2)}ds \tag{4.3}
$$
在此基础上，可以通过将文档一个接一个地添加到排名列表中，以迭代方式得出排名分布。 假设我们已经在排名列表中包含文档$x_j$，则在添加文档$x_u$时，如果文档$x_u$可以击败$x_jj$，则$x_j$的排名将增加1。 否则，$x_j$的等级将保持不变。 在数学上，可以将$x_j$排在位置$r$上的概率（表示为$P_j(r)$）计算如下：
$$
P_j^{(u)}(r)=P_j^{(u-1)}(r-1)P_{u,j}+P_j^{(u-1)}(r)(1-P_{u,j}) \tag{4.4}
$$
第三，利用等级分布，可以计算NDCG的期望值（称为SoftNDCG（为了便于参考，我们还将诸如SoftNDCG的目标函数称为替代指标。）），并在学习排序时使用$(1- SoftNDCG)$作为损失函数：
$$
L(f;x,y)=1-\frac{1}{Z_m}\sum_{j=1}^m{(2^{y_j}-1)}\sum_{r=1}^m{P_j(r)} \tag{4.5}
$$
为了通过最小化上述损失函数来学习排序模型$f$，可以使用神经网络作为模型，并采用梯度下降作为优化算法。

在[14]中，高斯过程用于进一步增强SoftRank算法，其中$\sigma_s$不再是预先指定的常数，而是学习的参数。 在[35]中，SoftRank方法进一步扩展为近似P@k和AP。相应的目标函数分别命名为SoftPC和SoftAP。

#### 4.2.1.2 排序的决策理论框架

在[37]中，提出了与SoftRank类似的想法，该想法使用决策理论框架来优化预期的评估措施。 首先，定义排序实例。 例如，实例可以是任何评估指标。 假设效用表示为$U(·)$，则将以下期望效用作为学习目标：
$$
\tilde{U}(w;x,y)=E_{p(s|X,w)}[U(s,y)] \tag{4.6}
$$
其中$w$表示排序函数的参数，而$s$是文档的排序分数。

根据以上定义，尽管实例本身可能是不连续不可微的，但它不包含任何模型参数，也不会给学习过程带来麻烦，实际上包含模型参数的是条件概率$p(s|x,w)$。

在[37]中，假设文档之间的独立性（即，$p(s|x,w)=\Pi_jp(s_j|x_j,w)$，并且使用广义线性模型[22]来定义$p(s_j|x_j,w)p$，每个单个文档的条件概率。 广义线性模型包括似然模型$p(y |\theta)$，输入和模型参数的线性组合$w^Tx$以及将参数$\theta$映射到实线的链接函数。 特别地，在[37]中将二项式函数（即$Bin(·)$）用作似然模型，并使用累积正态函数（即$\psi(·)$）来定义
概率链接功能：
$$
p(s_j|X,w)=Bin(s_j;\psi(w^Tx;0,\frac{1}{\pi}),m) \tag{4.7}
$$
其中$m$是文档的数量。

然后，该算法使期望效用最大化（等效地，负效用可以视为损失函数）。 特别地，使用具有分解高斯先验的近似贝叶斯推断[18]来学习模型参数。

注意，除了优化评估方法之外，决策理论框架还可以用于优化其他实例，例如，用户单击文档的可能性。



替代地优化基于度量的排名误差的连续且有区别的（有时甚至是凸的）界限。示例算法包括SVMmap [36]，SVMndcg [5]和PermuRank [33] .1。第三，可以选择使用能够优化非平滑目标的优化技术。例如，可以为此目的利用Boosting框架（相应的算法称为AdaRank [32]），或采用遗传算法进行优化（相应的算法称为RankGP [34]）。